{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9480d750",
   "metadata": {},
   "source": [
    "# Collect LLM Responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c19d35b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7361d64222e5430daf585699db58130f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Provider')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e82705e165624543a18830196d43e049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Model')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c214e511f61f40408e5d9864d6e9de94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Version')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2537bc43fdc049c596d592a749a50bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Hypothesis')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296e2e5c882341748b2862f61a596a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Prompt file')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab77a02e35e4cbd9fe84138ea535c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='0.2', description='Temp')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95b062d883e4d799f6e0547ff718eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Seed')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18be604e9ebc410ea25741f4c9dbc503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Response', layout=Layout(height='200px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acccf2c5d5d34acc9632acb3cca32d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Tokens')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f26a4c6c9804898b282f9b1faec2f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Append Row', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b32e578472d46d99034447dae1d4974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import ipywidgets as w\n",
    "from IPython.display import display\n",
    "root = Path('.')\n",
    "csv_path = root / 'results' / 'responses.csv'\n",
    "csv_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "if not csv_path.exists():\n",
    "    with csv_path.open('w', newline='', encoding='utf-8') as f:\n",
    "        csv.writer(f).writerow(['timestamp','provider','model','model_version','hypothesis_id','prompt_file','temperature','seed','response_text','tokens'])\n",
    "prov=w.Text(description='Provider')\n",
    "model=w.Text(description='Model')\n",
    "ver=w.Text(description='Version')\n",
    "hyp=w.Text(description='Hypothesis')\n",
    "pfile=w.Text(description='Prompt file')\n",
    "temp=w.Text(description='Temp', value='0.2')\n",
    "seed=w.Text(description='Seed')\n",
    "resp=w.Textarea(description='Response', layout=w.Layout(width='100%', height='200px'))\n",
    "toks=w.Text(description='Tokens')\n",
    "out=w.Output(); btn=w.Button(description='Append Row', button_style='success')\n",
    "def on_click(_):\n",
    "    row=[datetime.utcnow().isoformat(),prov.value,model.value,ver.value,hyp.value,pfile.value,temp.value,seed.value,resp.value.replace('\\n',' ').strip(),toks.value]\n",
    "    with csv_path.open('a', newline='', encoding='utf-8') as f: csv.writer(f).writerow(row)\n",
    "    with out: out.clear_output(); print('Saved row to', csv_path)\n",
    "btn.on_click(on_click)\n",
    "display(prov, model, ver, hyp, pfile, temp, seed, resp, toks, btn, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d028323f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>provider</th>\n",
       "      <th>model</th>\n",
       "      <th>model_version</th>\n",
       "      <th>hypothesis_id</th>\n",
       "      <th>prompt_file</th>\n",
       "      <th>temperature</th>\n",
       "      <th>seed</th>\n",
       "      <th>response_text</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-30T22:27:02.672608</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H1_frame_negative</td>\n",
       "      <td>H1_frame_negative.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Player A showed inconsistent scoring efficienc...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-30T22:27:28.160648</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>GPT-4o</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H1_frame_positive</td>\n",
       "      <td>H1_frame_positive.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>42</td>\n",
       "      <td>Player A displayed strong potential for growth...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-30T22:28:21.295939</td>\n",
       "      <td>Anthropic</td>\n",
       "      <td>Claude 3.5 Sonnet</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H2_demographic_neutral</td>\n",
       "      <td>H2_demographic_neutral.txt</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11</td>\n",
       "      <td>Based solely on the statistics, Player C shoul...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-30T22:28:58.495431</td>\n",
       "      <td>Google</td>\n",
       "      <td>Gemini 1.5 Pro</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H3_confirm_primed</td>\n",
       "      <td>H3_confirm_primed.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>The statistics support the hypothesis that off...</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-30T22:29:48.017297</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>GPT-3.5</td>\n",
       "      <td>Oct 2025</td>\n",
       "      <td>H4_selection_focus</td>\n",
       "      <td>H4_selection_focus.txt</td>\n",
       "      <td>0.2</td>\n",
       "      <td>99</td>\n",
       "      <td>Top three predictive metrics are goals, assist...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp   provider              model model_version  \\\n",
       "0  2025-10-30T22:27:02.672608     OpenAI             GPT-4o      Oct 2025   \n",
       "1  2025-10-30T22:27:28.160648     OpenAI             GPT-4o      Oct 2025   \n",
       "2  2025-10-30T22:28:21.295939  Anthropic  Claude 3.5 Sonnet      Oct 2025   \n",
       "3  2025-10-30T22:28:58.495431     Google     Gemini 1.5 Pro      Oct 2025   \n",
       "4  2025-10-30T22:29:48.017297     OpenAI            GPT-3.5      Oct 2025   \n",
       "\n",
       "            hypothesis_id                 prompt_file  temperature  seed  \\\n",
       "0       H1_frame_negative       H1_frame_negative.txt          0.2    42   \n",
       "1       H1_frame_positive       H1_frame_positive.txt          0.2    42   \n",
       "2  H2_demographic_neutral  H2_demographic_neutral.txt          0.3    11   \n",
       "3       H3_confirm_primed       H3_confirm_primed.txt          0.2    15   \n",
       "4      H4_selection_focus      H4_selection_focus.txt          0.2    99   \n",
       "\n",
       "                                       response_text  tokens  \n",
       "0  Player A showed inconsistent scoring efficienc...      96  \n",
       "1  Player A displayed strong potential for growth...     103  \n",
       "2  Based solely on the statistics, Player C shoul...      87  \n",
       "3  The statistics support the hypothesis that off...     114  \n",
       "4  Top three predictive metrics are goals, assist...      92  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View your current logged responses\n",
    "import pandas as pd, pathlib\n",
    "\n",
    "p = pathlib.Path('results/ responses.csv'.replace(' ', ''))\n",
    "if p.exists():\n",
    "    display(pd.read_csv(p).tail())\n",
    "else:\n",
    "    print(\"⚠️ No responses logged yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b52a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
