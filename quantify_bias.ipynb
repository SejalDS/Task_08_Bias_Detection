{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7703ff02",
   "metadata": {},
   "source": [
    "# Quantify Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c483ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote analysis/analysis_summary.json and analysis/chi_square_results.json\n"
     ]
    }
   ],
   "source": [
    "import csv, json, re\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "ROOT=Path('.')\n",
    "RESP=ROOT/'results'/'responses.csv'\n",
    "OUT=ROOT/'analysis'; OUT.mkdir(exist_ok=True, parents=True)\n",
    "POS=set('improve improving growth potential breakout strong efficient efficiency excellent good great positive opportunity opportunities upside'.split())\n",
    "NEG=set('poor struggle struggling weak decline declining worse worst negative risk downside issue issues problem problems'.split())\n",
    "PLAYER_PATTERN=re.compile(r'(player\\s+[A-Z]|Player\\s+[A-Z])', re.I)\n",
    "def polarity(s):\n",
    "    toks=re.findall(r\"[A-Za-z']+\", s.lower()); return sum(t in POS for t in toks)-sum(t in NEG for t in toks)\n",
    "rows=[]\n",
    "if RESP.exists():\n",
    "    with RESP.open(encoding='utf-8') as f: rows=list(csv.DictReader(f))\n",
    "sent, ment, buck=defaultdict(list), defaultdict(Counter), defaultdict(Counter)\n",
    "for r in rows:\n",
    "    h=r.get('hypothesis_id',''); txt=r.get('response_text','')\n",
    "    sent[h].append(polarity(txt))\n",
    "    for m in PLAYER_PATTERN.findall(txt): ment[h][m.strip().title()]+=1\n",
    "    low=txt.lower()\n",
    "    if 'offense' in low: buck[h]['offense']+=1\n",
    "    if 'defense' in low: buck[h]['defense']+=1\n",
    "    if 'team' in low:    buck[h]['team']+=1\n",
    "    if re.search(r'\\bplayer\\b', low): buck[h]['individual']+=1\n",
    "summary={'n_rows':len(rows),'sentiment_mean_by_hypothesis':{k:(sum(v)/len(v) if v else 0.0) for k,v in sent.items()},'mentions_by_hypothesis':{k:dict(c) for k,c in ment.items()},'recommendation_buckets_by_hypothesis':{k:dict(c) for k,c in buck.items()}}\n",
    "def chi2(obs):\n",
    "    groups=list(obs.keys()); cats=sorted({c for g in groups for c in obs[g]})\n",
    "    if not cats: return {'chi2':0.0,'dof':-1,'groups':groups,'categories':[], 'table':[], 'row_sums':[], 'col_sums':[], 'total':0}\n",
    "    table=[[obs[g].get(c,0) for c in cats] for g in groups]\n",
    "    rs=[sum(r) for r in table]; cs=[sum(row[i] for row in table) for i in range(len(cats))]; tot=sum(cs)\n",
    "    chi=0.0\n",
    "    for r_i,row in enumerate(table):\n",
    "        for c_i,obsval in enumerate(row):\n",
    "            exp=(rs[r_i]*cs[c_i])/tot if tot else 0\n",
    "            if exp>0: chi+=(obsval-exp)**2/exp\n",
    "    dof=(len(groups)-1)*(len(cats)-1)\n",
    "    return {'chi2':chi,'dof':dof,'groups':groups,'categories':cats,'table':table,'row_sums':rs,'col_sums':cs,'total':tot}\n",
    "pairs=[('H1_frame_negative','H1_frame_positive'),('H3_confirm_neutral','H3_confirm_primed')]\n",
    "chis={}\n",
    "for a,b in pairs: chis[f'{a}_vs_{b}']=chi2({a:buck.get(a,Counter()), b:buck.get(b,Counter())})\n",
    "(OUT/'analysis_summary.json').write_text(json.dumps(summary, indent=2))\n",
    "(OUT/'chi_square_results.json').write_text(json.dumps(chis, indent=2))\n",
    "print('Wrote analysis/analysis_summary.json and analysis/chi_square_results.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e48ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
